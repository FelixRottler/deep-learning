{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import vocab\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/i540927/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"twitter_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/i540927/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "Punctuation\n",
      "\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Import the english stop words list from NLTK\n",
    "stopwords_english = stopwords.words('english') \n",
    "\n",
    "('Stop words\\n')\n",
    "print(stopwords_english)\n",
    "\n",
    "print('\\nPunctuation\\n')\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet:str):\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)    \n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "\n",
    "    # tokenize tweets\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    tweets_clean = []\n",
    "\n",
    "    for word in tweet_tokens: # Go through every word in your tokens list\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "            word not in string.punctuation):  # remove punctuation\n",
    "            tweets_clean.append(word)\n",
    "    stemmer = PorterStemmer() \n",
    "\n",
    "    # Create an empty list to store the stems\n",
    "    tweets_stem = [] \n",
    "\n",
    "    for word in tweets_clean:\n",
    "        stem_word = stemmer.stem(word)  # stemming word\n",
    "        tweets_stem.append(stem_word)  # append to the list\n",
    "\n",
    "    return tweets_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, positive_tweets, negative_tweets,vectors=None,tokenize=lambda x:x.split(),pad_token=\"<pad>\",unk_token=\"<unk>\"):\n",
    "        self.tweets = []\n",
    "      \n",
    "        specials=[\"<pad>\",\"<unk>\"]\n",
    "\n",
    "        def yield_tokens(data):\n",
    "            for tweet in data:\n",
    "                tokens = tokenize(tweet)\n",
    "                yield tokens\n",
    "            \n",
    "        self.vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "            yield_tokens(negative_tweets+positive_tweets),\n",
    "            special_first=True,\n",
    "            specials=specials)\n",
    "        self.pad_idx = self.vocab[\"<pad>\"]\n",
    "        self.vocab.set_default_index(self.vocab[\"<unk>\"])\n",
    "        \n",
    "\n",
    "        for p_tweet in positive_tweets:\n",
    "            tokens = tokenize(p_tweet)\n",
    "            self.tweets.append((1, self.vocab.forward(tokens)))\n",
    "        for n_tweet in negative_tweets:\n",
    "            tokens = tokenize(n_tweet)\n",
    "            self.tweets.append((0, self.vocab.forward(tokens)))\n",
    "       \n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tweets[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "            # batch in that case is List of batches that contain the elements of the iterator\n",
    "        text_list = []\n",
    "        target_list=[]\n",
    "        len_list=[]\n",
    "        \n",
    "        for (label,x) in batch:\n",
    "            x = torch.tensor(x, dtype=torch.int64)\n",
    "            text_list.append(x)  \n",
    "            target_list.append(label)\n",
    "            len_list.append(len(x))\n",
    "\n",
    "        len_list = torch.tensor(len_list,dtype=torch.int64)\n",
    "        sorted_lens, sorted_idx = torch.sort(len_list,descending=True)\n",
    "        target_list = torch.tensor(target_list, dtype=torch.int64)[sorted_idx]\n",
    "        text_list = pad_sequence(text_list, batch_first=True)[sorted_idx]\n",
    "        \n",
    "        return text_list,target_list, sorted_lens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = twitter_samples.strings(\"positive_tweets.json\")\n",
    "negative_tweets = twitter_samples.strings(\"negative_tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweet_dataset = TweetDataset(positive_tweets,negative_tweets,tokenize=process_tweet)\n",
    "\n",
    "\n",
    "n_train = int(0.8*len(tweet_dataset))\n",
    "n_test = len(tweet_dataset)- n_train\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(tweet_dataset,[n_train,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=TweetDataset.collate_fn,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset ,batch_size=64,collate_fn=TweetDataset.collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for text,target,lens in train_loader:\n",
    "    print(lens.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TweetClassification(torch.nn.Module):\n",
    "    def __init__(self,vocab_size, \n",
    "                        input_size, \n",
    "                        hidden_size,\n",
    "                        output_size,\n",
    "                        bidirectional=True,\n",
    "                        padding_idx=0):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.pad_idx = padding_idx\n",
    "        self.relu = torch.nn.ReLU()\n",
    "       \n",
    "        self.embeddings = torch.nn.Embedding(vocab_size,input_size,padding_idx=padding_idx)\n",
    "        self.lstm = torch.nn.LSTM(input_size=input_size,\n",
    "                                    hidden_size=hidden_size, \n",
    "                                    bidirectional=bidirectional,\n",
    "                                    batch_first=True,\n",
    "                                    dropout=0.3)\n",
    "        if bidirectional:\n",
    "            self.fc = torch.nn.Linear(in_features = 2*hidden_size,out_features=hidden_size)\n",
    "        else:\n",
    "            self.fc = torch.nn.Linear(in_features = hidden_size,out_features=hidden_size)\n",
    "        self.predictor = torch.nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        # Text dim = BATCH_SIZE,MAX_SEQ_LEN and text_lengths dim = BATCH_SIZE\n",
    "        # When passing BATCH_SIZE,MAX_SEQ_LEN through the embedding layer then for each value in the sequence we will get a d-dimensional vector\n",
    "        embeddings = self.embeddings(text)\n",
    "        # embeddings dim = BATCH_SIZE, MAX_SEQ_LEN, EMB_DIM\n",
    "\n",
    "        packed_embeddings = torch.nn.utils.rnn.pack_padded_sequence(embeddings, text_lengths, batch_first=True)\n",
    "\n",
    "        # packed_output dim = BATCH_SIZE,MAX_SEQ_LEN, HIDDEN_DIM\n",
    "        # h_n dim = NUM_DIR*NUM_LAYERS,BATCH_SIZE, HIDDEN_DIM\n",
    "        # In case of a BiLSTM it means that we have for each layer and for each BATCH a vector of size HIDDEN_DIM\n",
    "        # Since BiLSTM has two directions it means dim = 2,BATCH_SIZE,HIDDEN_DIM \n",
    "        packed_output,(h_n,_) = self.lstm(packed_embeddings)\n",
    "       \n",
    "       \n",
    "        # To use both directions we concat for all batches all the vectors\n",
    "        # hidden dim= BATCH_SIZE, 2*HIDDEN_SIZE\n",
    "        hidden = torch.cat([h_n[0,:,:],h_n[1,:,:]],dim=1)\n",
    "\n",
    "        # Which can then be passed into the dense layer\n",
    "        output = self.relu(self.fc(hidden))\n",
    "        return self.predictor(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "----------\n",
      "train Loss: 25.3479 Acc: 0.8031\n",
      "test Loss: 8.7461 Acc: 0.9515\n",
      "Epoch 1/10\n",
      "----------\n",
      "train Loss: 5.6989 Acc: 0.9699\n",
      "test Loss: 4.2340 Acc: 0.9755\n",
      "Epoch 2/10\n",
      "----------\n",
      "train Loss: 2.6198 Acc: 0.9866\n",
      "test Loss: 2.4255 Acc: 0.9865\n",
      "Epoch 3/10\n",
      "----------\n",
      "train Loss: 1.4917 Acc: 0.9935\n",
      "test Loss: 1.7495 Acc: 0.9895\n",
      "Epoch 4/10\n",
      "----------\n",
      "train Loss: 0.9920 Acc: 0.9951\n",
      "test Loss: 1.8436 Acc: 0.9890\n",
      "Epoch 5/10\n",
      "----------\n",
      "train Loss: 0.6555 Acc: 0.9966\n",
      "test Loss: 1.4291 Acc: 0.9905\n",
      "Epoch 6/10\n",
      "----------\n",
      "train Loss: 0.5365 Acc: 0.9978\n",
      "test Loss: 1.3239 Acc: 0.9925\n",
      "Epoch 7/10\n",
      "----------\n",
      "train Loss: 0.3499 Acc: 0.9985\n",
      "test Loss: 1.4089 Acc: 0.9915\n",
      "Epoch 8/10\n",
      "----------\n",
      "train Loss: 0.2673 Acc: 0.9989\n",
      "test Loss: 1.5698 Acc: 0.9910\n",
      "Epoch 9/10\n",
      "----------\n",
      "train Loss: 0.1993 Acc: 0.9991\n",
      "test Loss: 1.6171 Acc: 0.9910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=25):\n",
    "    model.to(device)\n",
    "    accuracy =[]\n",
    "    losses=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
    "        print(\"-\"*10)\n",
    "\n",
    "        for phase in [\"train\",\"test\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for texts,targets,lens in dataloaders[phase]:\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    x = texts.to(device)\n",
    "                    y = targets.to(device)\n",
    "\n",
    "                    outputs = model(x,lens).squeeze()\n",
    "                    loss = criterion(outputs,y.float())\n",
    "                \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * x.shape[0]\n",
    "                running_corrects += torch.sum((torch.round(torch.sigmoid(outputs)) ==  y)).item()\n",
    "            epoch_loss = running_loss / len(dataloaders[phase])\n",
    "            epoch_accuracy = running_corrects / len(dataloaders[phase].dataset)\n",
    "            if phase =='test':\n",
    "                losses.append(epoch_loss)\n",
    "                accuracy.append(epoch_accuracy)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_accuracy))\n",
    "    print()\n",
    "    return losses, accuracy\n",
    "        \n",
    "input_size= 16\n",
    "hidden_size = 32\n",
    "vocab_size = len(tweet_dataset.vocab)\n",
    "output_size = 1\n",
    "bidirectional = True\n",
    "\n",
    "crit = torch.nn.BCEWithLogitsLoss()\n",
    "net = TweetClassification(vocab_size,\n",
    "                            input_size,\n",
    "                            hidden_size,\n",
    "                            output_size,\n",
    "                            padding_idx=tweet_dataset.pad_idx,\n",
    "                            bidirectional=bidirectional)\n",
    "optim = torch.optim.Adam(net.parameters())\n",
    "\n",
    "EPOCHS = 10\n",
    "dataloaders ={\"train\":train_loader,\"test\":test_loader}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "losses, accuracy = train_model(net,dataloaders,crit,optim,device,num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f84d1db3760>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Uber_Delhi no supercars &amp; now no ice cream in so many Gurgaon locations :-( pls add more locations!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2199\n",
    "\n",
    "print(negative_tweets[i])\n",
    "x=tweet_dataset.vocab.forward(process_tweet(negative_tweets[i]))\n",
    "lens = torch.tensor([len(x)],dtype=torch.int64)\n",
    "x = torch.tensor(x).unsqueeze(0)\n",
    "\n",
    "net.eval()\n",
    "torch.round(torch.sigmoid(net(x,lens))).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence autoencoder with Twitter Sentiment Analysis Dataset\n",
    "- uses stacked lstm as encoder and decoder\n",
    "- takes the hidden state of the encoder and uses it as hidden state for each timestep at the decoder\n",
    "- open questions\n",
    "    - can MSELoss be used? (input and output are n-dimensional vectors)\n",
    "    - if not what should the loss be"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56f069e7f80ff7150fb1516d40bbe80842093e730232ba1b152d381f375fd298"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('dl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
